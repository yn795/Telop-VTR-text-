<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ブラウザで動画OCRを実行</title>
    <!-- OpenCV.jsの読み込み -->
    <script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>
    <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4.0.2/dist/tesseract.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            margin: 20px;
        }
        video, canvas {
            margin-top: 20px;
            max-width: 90%;
            height: auto;
        }
        textarea {
            width: 90%;
            height: 150px;
            margin-top: 20px;
        }
        .button {
            margin: 10px;
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <h1>ブラウザで動画OCRを実行</h1>

    <!-- 動画アップロード -->
    <input type="file" id="videoUpload" accept="video/mp4" class="button">
    <br>

    <!-- 動画プレビュー -->
    <video id="videoPlayer" controls>
        お使いのブラウザは動画タグをサポートしていません。
    </video>
    <br>

    <!-- テキスト抽出ボタン -->
    <button id="extractButton" class="button" style="display: none;">テキスト抽出</button>
    <br>

    <!-- テキスト出力 -->
    <h2>OCR結果</h2>
    <textarea id="ocrResult" readonly></textarea>
    <br>
    <button id="copyButton" class="button">結果をコピー</button>

    <p>ご視聴ありがとうございました。</p>

    <canvas id="canvas" style="display:none;"></canvas>

    <script>
        // OpenCV.jsのロード完了を待つ
        let cvReady = false;
        function onOpenCvReady() {
            cvReady = true;
            console.log("OpenCV.js is ready.");
        }
        // OpenCV.jsがロードされたらonOpenCvReadyを呼び出す
        document.addEventListener('DOMContentLoaded', () => {
            if (typeof cv === 'undefined') {
                console.error('Failed to load OpenCV.js');
            } else {
                cv['onRuntimeInitialized'] = onOpenCvReady;
            }
        });

        const videoUpload = document.getElementById("videoUpload");
        const videoPlayer = document.getElementById("videoPlayer");
        const extractButton = document.getElementById("extractButton");
        const ocrResult = document.getElementById("ocrResult");
        const copyButton = document.getElementById("copyButton");
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");

        // Tesseractのインスタンスを初期化
        const worker = Tesseract.createWorker({
            logger: m => console.log(m) // ログをコンソールに出力
        });

        (async () => {
            await worker.load();
            await worker.loadLanguage('jpn');
            await worker.initialize('jpn');
        })();

        // 動画アップロード処理
        videoUpload.addEventListener("change", (event) => {
            const file = event.target.files[0];
            if (file) {
                const url = URL.createObjectURL(file);
                videoPlayer.src = url;

                // テキスト抽出ボタンを表示
                extractButton.style.display = "inline-block";

                // 初期化
                ocrResult.value = "";
            }
        });

        // テキスト抽出処理
        extractButton.addEventListener("click", async () => {
            if (!videoPlayer.src) {
                alert("動画をアップロードしてください。");
                return;
            }

            if (!cvReady) {
                alert("OpenCV.jsがまだロードされていません。少々お待ちください。");
                return;
            }

            ocrResult.value = "処理中です。少々お待ちください...";

            const video = videoPlayer;
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            // フレームを抽出してOCR処理を実行
            const interval = 1000; // ミリ秒単位（例: 1000msごとにフレーム抽出）
            const ocrResults = [];

            // 動画を最初から再生
            video.currentTime = 0;

            // 動画のメタデータが読み込まれるのを待つ
            await new Promise(resolve => {
                video.onloadedmetadata = () => {
                    resolve();
                };
            });

            const processFrame = async () => {
                if (video.currentTime >= video.duration) {
                    // 処理が終了したら結果を結合して表示
                    ocrResult.value = ocrResults.join("\n");
                    await worker.terminate();
                    return;
                }

                // 現在のフレームをキャンバスに描画
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                // キャンバスから画像データを取得
                let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

                // OpenCV.jsを使用した前処理
                let src = cv.matFromImageData(imageData);
                let gray = new cv.Mat();
                cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

                // ノイズ除去
                let denoised = new cv.Mat();
                cv.medianBlur(gray, denoised, 3);

                // 二値化
                let binary = new cv.Mat();
                cv.adaptiveThreshold(denoised, binary, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 31, 2);

                // 画像データを再取得
                cv.imshow('canvas', binary);
                imageData = canvas.toDataURL("image/png");

                // メモリ解放
                src.delete(); gray.delete(); denoised.delete(); binary.delete();

                try {
                    const { data: { text } } = await worker.recognize(imageData);
                    ocrResults.push(text.trim());
                } catch (error) {
                    console.error("OCRエラー:", error);
                }

                // 次のフレームを処理
                video.currentTime += interval / 1000;
                await processFrame();
            };

            processFrame();
        });

        // コピー処理
        copyButton.addEventListener("click", () => {
            ocrResult.select();
            document.execCommand("copy");
            alert("OCR結果をコピーしました！");
        });
    </script>
</body>
</html>
